// LangGraph çŠ¶æ€æœºå’Œè®°å¿†ç®¡ç†
import {
  START,
  END,
  MessagesAnnotation,
  StateGraph,
  MemorySaver,
} from "@langchain/langgraph";

// å·¥å…·å’Œ UUID ç”Ÿæˆ
import { v4 as uuidv4 } from "uuid";

// LLM æ¨¡å‹å’Œæ¶ˆæ¯å¤„ç†
import llm from "./utils/generate_mode.js";
import { trimMessages } from "@langchain/core/messages";

// CLI äº¤äº’
import readline from "node:readline/promises";
import { stdin as input, stdout as output } from "node:process";

// Prompt æ¨¡æ¿
import {
  ChatPromptTemplate,
  MessagesPlaceholder,
  PromptTemplate,
} from "@langchain/core/prompts";

// RAG ç›¸å…³æ¨¡å—
import { buildInMemoryRetriever, buildChromaRetriever } from "./rag/retriever.js";
import { createStuffDocumentsChain } from "langchain/chains/combine_documents";
import { createRetrievalChain } from "langchain/chains/retrieval";

// ç¯å¢ƒå˜é‡åŠ è½½
import dotenv from "dotenv";

// åŠ è½½ç¯å¢ƒå˜é‡
dotenv.config();

// === Google Gemini LLM æ¨¡å‹é…ç½® ===
// ä» generate_mode.js å¯¼å…¥å·²é…ç½®å¥½çš„ Google Gemini æ¨¡å‹å®ä¾‹
// é»˜è®¤ä½¿ç”¨ "gemini-2.5-flash" æ¨¡å‹ï¼Œæ”¯æŒæµå¼è¾“å‡º

// === RAG æ£€ç´¢å™¨é…ç½® ===
// ç¯å¢ƒå˜é‡é…ç½®ï¼šUSE_CHROMA=true ä½¿ç”¨ ChromaDBï¼Œå¦åˆ™ä½¿ç”¨å†…å­˜å­˜å‚¨
const USE_CHROMA = process.env.USE_CHROMA === 'true';
const CHROMA_URL = process.env.CHROMA_URL || 'http://localhost:8000';

// åˆå§‹åŒ–æ£€ç´¢å™¨ï¼ˆæ”¯æŒå†…å­˜å’Œ ChromaDB ä¸¤ç§æ¨¡å¼ï¼‰
const retriever = USE_CHROMA 
  ? await buildChromaRetriever()
  : await buildInMemoryRetriever();

console.log(`ğŸ”§ ä½¿ç”¨å‘é‡å­˜å‚¨ç±»å‹: ${USE_CHROMA ? 'ChromaDB (æŒä¹…æ€§)' : 'MemoryVectorStore (å†…å­˜)'}`);
console.log(`ğŸ“š çŸ¥è¯†åº“åˆå§‹åŒ–å®Œæˆï¼Œæ£€ç´¢å™¨å·²å‡†å¤‡å¥½`);

// === Prompt æ¨¡æ¿å®šä¹‰ ===
// å¸¸è§„å¯¹è¯ Prompt æ¨¡æ¿
const prompt = ChatPromptTemplate.fromMessages([
  ["system", "You are a helpful assistant. Answer clearly and concisely in Chinese."],
  new MessagesPlaceholder("messages"),
]);

// RAG ä¸“ç”¨ Prompt æ¨¡æ¿ï¼ˆåŒ…å«ä¸Šä¸‹æ–‡å’Œæ¥æºä¿¡æ¯ï¼‰
const ragPrompt = ChatPromptTemplate.fromMessages([
  [
    "system",
    [
      "You are a helpful assistant. Answer strictly based on the given CONTEXT.",
      "If the answer is not in the context, say you don't know.",
      "Use Chinese in your reply. At the end, list SOURCES (unique) from metadata.",
      "",
      "CONTEXT:",
      "{context}",
    ].join("\n"),
  ],
  new MessagesPlaceholder("chat_history"),
  ["human", "{input}"],
]);

// æ–‡æ¡£æ ¼å¼åŒ–æ¨¡æ¿ï¼ˆç”¨äº RAG æ˜¾ç¤ºæ¥æºï¼‰
const documentPrompt = PromptTemplate.fromTemplate(
  "SOURCE: {source}\n{page_content}"
);

// ç»„è£…åŸºç¡€å¯¹è¯é“¾ï¼šprompt -> æ¨¡å‹
const chain = prompt.pipe(llm);

// === æ¶ˆæ¯è£å‰ªå™¨é…ç½® ===
// é˜²æ­¢ä¸Šä¸‹æ–‡çª—å£æº¢å‡ºï¼Œæ§åˆ¶å†å²æ¶ˆæ¯é•¿åº¦
const trimmer = trimMessages({
  maxTokens: 1000, // å®‰å…¨ä¸Šé™ï¼Œé˜²æ­¢æ¨¡å‹çª—å£æº¢å‡º
  strategy: "last", // ä¿ç•™æœ€è¿‘çš„å¯¹è¯
  includeSystem: true, // å§‹ç»ˆä¿ç•™ç³»ç»Ÿæ¶ˆæ¯
  allowPartial: true, // å…è®¸æˆªæ–­è¿‡é•¿çš„å•æ¡æ¶ˆæ¯
  // ç®€æ˜“ Token ä¼°ç®—ï¼šä¸­æ–‡çº¦ 2 å­—ç¬¦ = 1 tokenï¼Œè‹±æ–‡çº¦ 4 å­—ç¬¦ = 1 token
  tokenCounter: (msgs) => {
    const text = msgs
      .map((m) =>
        typeof m.content === "string" ? m.content : JSON.stringify(m.content)
      )
      .join(" ");
    return Math.ceil(text.length / 3); // ä¸­æ–‡ä¼˜åŒ–çš„ä¼°ç®—
  },
});

// === æ¨¡å‹è°ƒç”¨èŠ‚ç‚¹å®šä¹‰ ===
/**
 * å¤„ç†çŠ¶æ€ä¸­çš„æ¶ˆæ¯ï¼Œè°ƒç”¨ LLM ç”Ÿæˆå›å¤
 * @param {typeof MessagesAnnotation.State} state - LangGraph çŠ¶æ€å¯¹è±¡
 * @returns {Object} è¿”å›æ–°çš„æ¶ˆæ¯çŠ¶æ€
 */
const callModel = async (state) => {
  // è£å‰ªå†å²æ¶ˆæ¯é˜²æ­¢ä¸Šä¸‹æ–‡è¿‡é•¿
  const trimmed = await trimmer.invoke(state.messages);
  // è°ƒç”¨åŸºç¡€å¯¹è¯é“¾ç”Ÿæˆå›å¤
  const response = await chain.invoke({ messages: trimmed });
  return { messages: response }; // è¿”å›ç»™ LangGraph çš„æ¶ˆæ¯çŠ¶æ€
};

// === StateGraph çŠ¶æ€æœºæ¶æ„ ===
// æ„å»ºå·¥ä½œæµï¼šSTART -> model -> END
const workflow = new StateGraph(MessagesAnnotation)
  .addNode("model", callModel) // æ·»åŠ æ¨¡å‹è°ƒç”¨èŠ‚ç‚¹
  .addEdge(START, "model")     // START èŠ‚ç‚¹è¿æ¥åˆ° model
  .addEdge("model", END);      // model èŠ‚ç‚¹è¿æ¥åˆ° END

// === è®°å¿†æ£€æŸ¥ç‚¹é…ç½® ===
// ä½¿ç”¨ MemorySaver å®ç°ä¼šè¯æŒä¹…åŒ–ï¼Œæ”¯æŒå¤šçº¿ç¨‹å¯¹è¯
const app = workflow.compile({ 
  checkpointer: new MemorySaver() 
});

console.log("ğŸ  çŠ¶æ€æœºå’Œè®°å¿†æ£€æŸ¥ç‚¹åˆå§‹åŒ–å®Œæˆ");

// === RAG æ£€ç´¢å¢å¼ºç”Ÿæˆé“¾ ===
// æ„å»ºæ–‡æ¡£ç»„åˆé“¾ï¼ˆå°†æ£€ç´¢åˆ°çš„æ–‡æ¡£ä¸ç”¨æˆ·æŸ¥è¯¢ç»“åˆï¼‰
const docChain = await createStuffDocumentsChain({
  llm, // å¤ç”¨ Google Gemini æ¨¡å‹å®ä¾‹
  prompt: ragPrompt, // ä½¿ç”¨ RAG ä¸“ç”¨çš„ Prompt æ¨¡æ¿
  documentPrompt, // æ–‡æ¡£æ ¼å¼åŒ–æ¨¡æ¿ï¼Œæ˜¾ç¤ºæ¥æºä¿¡æ¯
});

// æ„å»ºå®Œæ•´çš„ RAG æ£€ç´¢é“¾ï¼ˆæ£€ç´¢ + ç”Ÿæˆï¼‰
const ragChain = await createRetrievalChain({
  retriever, // ä½¿ç”¨åˆå§‹åŒ–çš„æ£€ç´¢å™¨
  combineDocsChain: docChain, // ä½¿ç”¨æ–‡æ¡£ç»„åˆé“¾
});

console.log("ğŸ”— RAG æ£€ç´¢å¢å¼ºç”Ÿæˆé“¾æ„å»ºå®Œæˆ");

// === å·¥å…·å‡½æ•° ===
/**
 * ä¾¿æ·çš„å•æ¬¡æ‰§è¡Œå‡½æ•°ï¼Œè¿”å› AI å›å¤å’Œçº¿ç¨‹ ID
 * @param {string} userText - ç”¨æˆ·è¾“å…¥å†…å®¹
 * @param {string} threadId - çº¿ç¨‹ IDï¼Œç”¨äºä¼šè¯è®°å¿†
 * @returns {Promise<{reply: string, threadId: string}>} AI å›å¤å’Œçº¿ç¨‹ ID
 */
export async function runTime(userText, threadId) {
  const config = { configurable: { thread_id: threadId ?? uuidv4() } };
  const output = await app.invoke(
    { messages: [{ role: "user", content: userText }] },
    config
  );
  const last = output.messages[output.messages.length - 1];
  return { reply: last.content, threadId: config.configurable.thread_id };
}

// === CLI äº¤äº’ä¸»ç¨‹åº ===
/**
 * ä¸» CLI äº¤äº’å‡½æ•°ï¼Œæ”¯æŒå¯¹è¯ã€RAG æ£€ç´¢å’Œä¼šè¯ç®¡ç†
 */
async function main() {
  let threadId = uuidv4();
  console.log("ğŸ” å½“å‰çº¿ç¨‹:", threadId);
  console.log("ğŸ’¬ èŠå¤©å¼€å§‹ã€‚å‘½ä»¤ï¼š/new å¼€æ–°ä¼šè¯, /rag <é—®é¢˜> çŸ¥è¯†åº“æ£€ç´¢, /exit é€€å‡º");
  console.log("ğŸ’¡ æç¤ºï¼šåœ¨å¯¹è¯ä¸­é‡åˆ°é—®é¢˜æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œ API å¯†é’¥é…ç½®\n");

  // åˆ›å»º readline æ¥å£ç”¨äºç”¨æˆ·è¾“å…¥
  const rl = readline.createInterface({ 
    input, 
    output,
    // å¢åŠ ä¿¡å·å¤„ç†
    terminal: true
  });
  
  // ä¼˜é›…åœ°å¤„ç†é€€å‡ºä¿¡å·
  process.on('SIGINT', () => {
    console.log("\n\nğŸ‘‹ æ¥æ”¶åˆ°é€€å‡ºä¿¡å·ï¼Œå†è§ï¼");
    rl.close();
    process.exit(0);
  });
  
  while (true) {
    try {
      const q = await rl.question("> ");
      const text = q.trim();
      if (!text) continue;

      // === å‘½ä»¤å¤„ç† ===
      if (text === "/exit") {
        break;
      }
      
      if (text === "/new") {
        threadId = uuidv4();
        console.log("âœ… æ–°çº¿ç¨‹:", threadId);
        continue;
      }
      
      // å¸®åŠ©å‘½ä»¤
      if (text === "/help" || text === "/h") {
        console.log("\nğŸ“š å¯ç”¨å‘½ä»¤ï¼š");
        console.log("  /new        - å¼€å§‹æ–°çš„å¯¹è¯çº¿ç¨‹");
        console.log("  /rag <é—®é¢˜>  - ä½¿ç”¨ RAG æ¨¡å¼æ£€ç´¢çŸ¥è¯†åº“");
        console.log("  /help (/h)  - æ˜¾ç¤ºè¿™ä¸ªå¸®åŠ©ä¿¡æ¯");
        console.log("  /exit       - é€€å‡ºç¨‹åº\n");
        continue;
      }

      // === RAG æ¨¡å¼ï¼šä»çŸ¥è¯†åº“æ£€ç´¢å¹¶å›ç­” ===
      if (text.startsWith("/rag")) {
        const question = text.slice(4).trim();
        if (!question) {
          console.log("âš ï¸  ç”¨æ³•: /rag <é—®é¢˜>");
          console.log("ğŸ“š ç¤ºä¾‹: /rag ä»€ä¹ˆæ˜¯ RAG?");
          continue;
        }
        try {
          console.log("ğŸ” æ­£åœ¨æ£€ç´¢çŸ¥è¯†åº“...");
          const result = await ragChain.invoke({ 
            input: question, 
            chat_history: [] // RAG æ¨¡å¼ä¸ä½¿ç”¨å†å²å¯¹è¯
          });
          // å¤„ç† RAG å“åº”ç»“æœ
          const reply = result?.answer ?? result?.output_text ?? "âš ï¸ æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯";
          console.log("ğŸ“š RAG:", reply);
        } catch (err) {
          console.error("âŒ RAG æ£€ç´¢å¤±è´¥ï¼š", err.message);
          if (err.message.includes('API')) {
            console.error("ğŸ’¡ è¯·æ£€æŸ¥ Google API å¯†é’¥æ˜¯å¦æ­£ç¡®é…ç½®");
          } else if (err.message.includes('network') || err.message.includes('ENOTFOUND')) {
            console.error("ğŸ’¡ è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸");
          }
        }
        continue;
      }

      // === å¸¸è§„å¯¹è¯æ¨¡å¼ï¼šä½¿ç”¨æµå¼è¾“å‡º ===
      const stream = await app.streamEvents(
        { messages: [{ role: "user", content: text }] },
        { version: "v2", configurable: { thread_id: threadId } }
      );

      let first = true;
      let hasContent = false;
      for await (const ev of stream) {
        if (ev.event === "on_chat_model_stream") {
          const chunk = ev.data?.chunk;
          // å…¼å®¹å¤„ç†ä¸åŒç±»å‹çš„ chunk å†…å®¹
          const piece = Array.isArray(chunk?.content)
            ? chunk.content
                .map((c) => (typeof c === "string" ? c : c?.text ?? ""))
                .join("")
            : chunk?.content ?? "";
          
          if (first && piece) {
            process.stdout.write("ğŸ¤–: ");
            first = false;
          }
          if (piece) {
            process.stdout.write(piece);
            hasContent = true;
          }
        }
      }
      
      if (!hasContent) {
        console.log("ğŸ¤–: æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•ç”Ÿæˆå›å¤ã€‚è¯·ç¨åå†è¯•ã€‚");
      } else {
        process.stdout.write("\n");
      }
      
    } catch (err) {
      console.error("âŒ è°ƒç”¨å¤±è´¥ï¼š", err.message);
      
      // æä¾›å…·ä½“çš„é”™è¯¯å¤„ç†å»ºè®®
      if (err.message.includes('API')) {
        console.error("ğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼š");
        console.error("   1. æ£€æŸ¥ .env æ–‡ä»¶ä¸­çš„ GOOGLE_API_KEY æ˜¯å¦æ­£ç¡®");
        console.error("   2. ç¡®è®¤ API å¯†é’¥æœ‰æ•ˆä¸”æœªè¶…å‡ºé…é¢");
      } else if (err.message.includes('network') || err.message.includes('timeout')) {
        console.error("ğŸ’¡ ç½‘ç»œç›¸å…³é—®é¢˜ï¼šè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œé˜²ç«å¢™è®¾ç½®");
      } else {
        console.error("ğŸ’¡ è¯·å°è¯•é‡æ–°è¾“å…¥æˆ–ä½¿ç”¨ /new å¼€å§‹æ–°å¯¹è¯");
      }
    }
  }

  rl.close();
  console.log("ğŸ‘‹ å†è§ï¼");
}

// è‡ªåŠ¨å¯åŠ¨ CLI äº¤äº’
main().catch(console.error);


